{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_i1q1TWG9zH"
   },
   "source": [
    "# Deep Crossentropy method\n",
    "\n",
    "In this section we'll extend your CEM implementation with neural networks! You will train a multi-layer neural network to solve simple continuous state space games. __Please make sure you're done with tabular crossentropy method from the previous notebook.__\n",
    "\n",
    "![img](https://watanimg.elwatannews.com/old_news_images/large/249765_Large_20140709045740_11.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:56:25.811185Z",
     "iopub.status.busy": "2024-10-06T02:56:25.811014Z",
     "iopub.status.idle": "2024-10-06T02:56:25.813055Z",
     "shell.execute_reply": "2024-10-06T02:56:25.812825Z",
     "shell.execute_reply.started": "2024-10-06T02:56:25.811170Z"
    },
    "id": "t4CJ1sRyG9zJ"
   },
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:56:26.127661Z",
     "iopub.status.busy": "2024-10-06T02:56:26.127525Z",
     "iopub.status.idle": "2024-10-06T02:56:26.452330Z",
     "shell.execute_reply": "2024-10-06T02:56:26.452010Z",
     "shell.execute_reply.started": "2024-10-06T02:56:26.127650Z"
    },
    "id": "_2zbc7ahG9zK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state vector dim = 4\n",
      "n_actions = 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\").env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "plt.imshow(env.render())\n",
    "print(\"state vector dim =\", state_dim)\n",
    "print(\"n_actions =\", n_actions)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:56:26.452971Z",
     "iopub.status.busy": "2024-10-06T02:56:26.452851Z",
     "iopub.status.idle": "2024-10-06T02:56:26.455992Z",
     "shell.execute_reply": "2024-10-06T02:56:26.455698Z",
     "shell.execute_reply.started": "2024-10-06T02:56:26.452963Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on CartPoleEnv in module gymnasium.envs.classic_control.cartpole object:\n",
      "\n",
      "class CartPoleEnv(gymnasium.core.Env)\n",
      " |  CartPoleEnv(render_mode: Optional[str] = None)\n",
      " |\n",
      " |  ## Description\n",
      " |\n",
      " |  This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson in\n",
      " |  [\"Neuronlike Adaptive Elements That Can Solve Difficult Learning Control Problem\"](https://ieeexplore.ieee.org/document/6313077).\n",
      " |  A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track.\n",
      " |  The pendulum is placed upright on the cart and the goal is to balance the pole by applying forces\n",
      " |   in the left and right direction on the cart.\n",
      " |\n",
      " |  ## Action Space\n",
      " |\n",
      " |  The action is a `ndarray` with shape `(1,)` which can take values `{0, 1}` indicating the direction\n",
      " |   of the fixed force the cart is pushed with.\n",
      " |\n",
      " |  - 0: Push cart to the left\n",
      " |  - 1: Push cart to the right\n",
      " |\n",
      " |  **Note**: The velocity that is reduced or increased by the applied force is not fixed and it depends on the angle\n",
      " |   the pole is pointing. The center of gravity of the pole varies the amount of energy needed to move the cart underneath it\n",
      " |\n",
      " |  ## Observation Space\n",
      " |\n",
      " |  The observation is a `ndarray` with shape `(4,)` with the values corresponding to the following positions and velocities:\n",
      " |\n",
      " |  | Num | Observation           | Min                 | Max               |\n",
      " |  |-----|-----------------------|---------------------|-------------------|\n",
      " |  | 0   | Cart Position         | -4.8                | 4.8               |\n",
      " |  | 1   | Cart Velocity         | -Inf                | Inf               |\n",
      " |  | 2   | Pole Angle            | ~ -0.418 rad (-24°) | ~ 0.418 rad (24°) |\n",
      " |  | 3   | Pole Angular Velocity | -Inf                | Inf               |\n",
      " |\n",
      " |  **Note:** While the ranges above denote the possible values for observation space of each element,\n",
      " |      it is not reflective of the allowed values of the state space in an unterminated episode. Particularly:\n",
      " |  -  The cart x-position (index 0) can be take values between `(-4.8, 4.8)`, but the episode terminates\n",
      " |     if the cart leaves the `(-2.4, 2.4)` range.\n",
      " |  -  The pole angle can be observed between  `(-.418, .418)` radians (or **±24°**), but the episode terminates\n",
      " |     if the pole angle is not in the range `(-.2095, .2095)` (or **±12°**)\n",
      " |\n",
      " |  ## Rewards\n",
      " |\n",
      " |  Since the goal is to keep the pole upright for as long as possible, a reward of `+1` for every step taken,\n",
      " |  including the termination step, is allotted. The threshold for rewards is 500 for v1 and 200 for v0.\n",
      " |\n",
      " |  ## Starting State\n",
      " |\n",
      " |  All observations are assigned a uniformly random value in `(-0.05, 0.05)`\n",
      " |\n",
      " |  ## Episode End\n",
      " |\n",
      " |  The episode ends if any one of the following occurs:\n",
      " |\n",
      " |  1. Termination: Pole Angle is greater than ±12°\n",
      " |  2. Termination: Cart Position is greater than ±2.4 (center of the cart reaches the edge of the display)\n",
      " |  3. Truncation: Episode length is greater than 500 (200 for v0)\n",
      " |\n",
      " |  ## Arguments\n",
      " |\n",
      " |  ```python\n",
      " |  import gymnasium as gym\n",
      " |  gym.make('CartPole-v1')\n",
      " |  ```\n",
      " |\n",
      " |  On reset, the `options` parameter allows the user to change the bounds used to determine\n",
      " |  the new random state.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      CartPoleEnv\n",
      " |      gymnasium.core.Env\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, render_mode: Optional[str] = None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  close(self)\n",
      " |      After the user has finished using the environment, close contains the code necessary to \"clean up\" the environment.\n",
      " |\n",
      " |      This is critical for closing rendering windows, database or HTTP connections.\n",
      " |      Calling ``close`` on an already closed environment has no effect and won't raise an error.\n",
      " |\n",
      " |  render(self)\n",
      " |      Compute the render frames as specified by :attr:`render_mode` during the initialization of the environment.\n",
      " |\n",
      " |      The environment's :attr:`metadata` render modes (`env.metadata[\"render_modes\"]`) should contain the possible\n",
      " |      ways to implement the render modes. In addition, list versions for most render modes is achieved through\n",
      " |      `gymnasium.make` which automatically applies a wrapper to collect rendered frames.\n",
      " |\n",
      " |      Note:\n",
      " |          As the :attr:`render_mode` is known during ``__init__``, the objects used to render the environment state\n",
      " |          should be initialised in ``__init__``.\n",
      " |\n",
      " |      By convention, if the :attr:`render_mode` is:\n",
      " |\n",
      " |      - None (default): no render is computed.\n",
      " |      - \"human\": The environment is continuously rendered in the current display or terminal, usually for human consumption.\n",
      " |        This rendering should occur during :meth:`step` and :meth:`render` doesn't need to be called. Returns ``None``.\n",
      " |      - \"rgb_array\": Return a single frame representing the current state of the environment.\n",
      " |        A frame is a ``np.ndarray`` with shape ``(x, y, 3)`` representing RGB values for an x-by-y pixel image.\n",
      " |      - \"ansi\": Return a strings (``str``) or ``StringIO.StringIO`` containing a terminal-style text representation\n",
      " |        for each time step. The text can include newlines and ANSI escape sequences (e.g. for colors).\n",
      " |      - \"rgb_array_list\" and \"ansi_list\": List based version of render modes are possible (except Human) through the\n",
      " |        wrapper, :py:class:`gymnasium.wrappers.RenderCollection` that is automatically applied during ``gymnasium.make(..., render_mode=\"rgb_array_list\")``.\n",
      " |        The frames collected are popped after :meth:`render` is called or :meth:`reset`.\n",
      " |\n",
      " |      Note:\n",
      " |          Make sure that your class's :attr:`metadata` ``\"render_modes\"`` key includes the list of supported modes.\n",
      " |\n",
      " |      .. versionchanged:: 0.25.0\n",
      " |\n",
      " |          The render function was changed to no longer accept parameters, rather these parameters should be specified\n",
      " |          in the environment initialised, i.e., ``gymnasium.make(\"CartPole-v1\", render_mode=\"human\")``\n",
      " |\n",
      " |  reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None)\n",
      " |      Resets the environment to an initial internal state, returning an initial observation and info.\n",
      " |\n",
      " |      This method generates a new starting state often with some randomness to ensure that the agent explores the\n",
      " |      state space and learns a generalised policy about the environment. This randomness can be controlled\n",
      " |      with the ``seed`` parameter otherwise if the environment already has a random number generator and\n",
      " |      :meth:`reset` is called with ``seed=None``, the RNG is not reset.\n",
      " |\n",
      " |      Therefore, :meth:`reset` should (in the typical use case) be called with a seed right after initialization and then never again.\n",
      " |\n",
      " |      For Custom environments, the first line of :meth:`reset` should be ``super().reset(seed=seed)`` which implements\n",
      " |      the seeding correctly.\n",
      " |\n",
      " |      .. versionchanged:: v0.25\n",
      " |\n",
      " |          The ``return_info`` parameter was removed and now info is expected to be returned.\n",
      " |\n",
      " |      Args:\n",
      " |          seed (optional int): The seed that is used to initialize the environment's PRNG (`np_random`).\n",
      " |              If the environment does not already have a PRNG and ``seed=None`` (the default option) is passed,\n",
      " |              a seed will be chosen from some source of entropy (e.g. timestamp or /dev/urandom).\n",
      " |              However, if the environment already has a PRNG and ``seed=None`` is passed, the PRNG will *not* be reset.\n",
      " |              If you pass an integer, the PRNG will be reset even if it already exists.\n",
      " |              Usually, you want to pass an integer *right after the environment has been initialized and then never again*.\n",
      " |              Please refer to the minimal example above to see this paradigm in action.\n",
      " |          options (optional dict): Additional information to specify how the environment is reset (optional,\n",
      " |              depending on the specific environment)\n",
      " |\n",
      " |      Returns:\n",
      " |          observation (ObsType): Observation of the initial state. This will be an element of :attr:`observation_space`\n",
      " |              (typically a numpy array) and is analogous to the observation returned by :meth:`step`.\n",
      " |          info (dictionary):  This dictionary contains auxiliary information complementing ``observation``. It should be analogous to\n",
      " |              the ``info`` returned by :meth:`step`.\n",
      " |\n",
      " |  step(self, action)\n",
      " |      Run one timestep of the environment's dynamics using the agent actions.\n",
      " |\n",
      " |      When the end of an episode is reached (``terminated or truncated``), it is necessary to call :meth:`reset` to\n",
      " |      reset this environment's state for the next episode.\n",
      " |\n",
      " |      .. versionchanged:: 0.26\n",
      " |\n",
      " |          The Step API was changed removing ``done`` in favor of ``terminated`` and ``truncated`` to make it clearer\n",
      " |          to users when the environment had terminated or truncated which is critical for reinforcement learning\n",
      " |          bootstrapping algorithms.\n",
      " |\n",
      " |      Args:\n",
      " |          action (ActType): an action provided by the agent to update the environment state.\n",
      " |\n",
      " |      Returns:\n",
      " |          observation (ObsType): An element of the environment's :attr:`observation_space` as the next observation due to the agent actions.\n",
      " |              An example is a numpy array containing the positions and velocities of the pole in CartPole.\n",
      " |          reward (SupportsFloat): The reward as a result of taking the action.\n",
      " |          terminated (bool): Whether the agent reaches the terminal state (as defined under the MDP of the task)\n",
      " |              which can be positive or negative. An example is reaching the goal state or moving into the lava from\n",
      " |              the Sutton and Barton, Gridworld. If true, the user needs to call :meth:`reset`.\n",
      " |          truncated (bool): Whether the truncation condition outside the scope of the MDP is satisfied.\n",
      " |              Typically, this is a timelimit, but could also be used to indicate an agent physically going out of bounds.\n",
      " |              Can be used to end the episode prematurely before a terminal state is reached.\n",
      " |              If true, the user needs to call :meth:`reset`.\n",
      " |          info (dict): Contains auxiliary diagnostic information (helpful for debugging, learning, and logging).\n",
      " |              This might, for instance, contain: metrics that describe the agent's performance state, variables that are\n",
      " |              hidden from observations, or individual reward terms that are combined to produce the total reward.\n",
      " |              In OpenAI Gym <v26, it contains \"TimeLimit.truncated\" to distinguish truncation and termination,\n",
      " |              however this is deprecated in favour of returning terminated and truncated variables.\n",
      " |          done (bool): (Deprecated) A boolean value for if the episode has ended, in which case further :meth:`step` calls will\n",
      " |              return undefined results. This was removed in OpenAI Gym v26 in favor of terminated and truncated attributes.\n",
      " |              A done signal may be emitted for different reasons: Maybe the task underlying the environment was solved successfully,\n",
      " |              a certain timelimit was exceeded, or the physics simulation has entered an invalid state.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {}\n",
      " |\n",
      " |  __orig_bases__ = (gymnasium.core.Env[numpy.ndarray, typing.Union[int, ...\n",
      " |\n",
      " |  __parameters__ = ()\n",
      " |\n",
      " |  metadata = {'render_fps': 50, 'render_modes': ['human', 'rgb_array']}\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gymnasium.core.Env:\n",
      " |\n",
      " |  __enter__(self)\n",
      " |      Support with-statement for the environment.\n",
      " |\n",
      " |  __exit__(self, *args: 'Any')\n",
      " |      Support with-statement for the environment and closes the environment.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Returns a string of the environment with :attr:`spec` id's if :attr:`spec.\n",
      " |\n",
      " |      Returns:\n",
      " |          A string identifying the environment\n",
      " |\n",
      " |  get_wrapper_attr(self, name: 'str') -> 'Any'\n",
      " |      Gets the attribute `name` from the environment.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from gymnasium.core.Env:\n",
      " |\n",
      " |  unwrapped\n",
      " |      Returns the base non-wrapped environment.\n",
      " |\n",
      " |      Returns:\n",
      " |          Env: The base non-wrapped :class:`gymnasium.Env` instance\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gymnasium.core.Env:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  np_random\n",
      " |      Returns the environment's internal :attr:`_np_random` that if not set will initialise with a random seed.\n",
      " |\n",
      " |      Returns:\n",
      " |          Instances of `np.random.Generator`\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from gymnasium.core.Env:\n",
      " |\n",
      " |  render_mode = None\n",
      " |\n",
      " |  reward_range = (-inf, inf)\n",
      " |\n",
      " |  spec = None\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |\n",
      " |  __class_getitem__(...)\n",
      " |      Parameterizes a generic class.\n",
      " |\n",
      " |      At least, parameterizing a generic class is the *main* thing this\n",
      " |      method does. For example, for some generic class `Foo`, this is called\n",
      " |      when we do `Foo[int]` - there, with `cls=Foo` and `params=int`.\n",
      " |\n",
      " |      However, note that this method is also called when defining generic\n",
      " |      classes in the first place with `class Foo[T]: ...`.\n",
      " |\n",
      " |  __init_subclass__(...)\n",
      " |      Function to initialize subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(env.unwrapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z72_alhdG9zK"
   },
   "source": [
    "# Neural Network Policy\n",
    "\n",
    "For this assignment we'll utilize the simplified neural network implementation from __[Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)__. Here's what you'll need:\n",
    "\n",
    "* `agent.partial_fit(states, actions)` - make a single training pass over the data. Maximize the probability of :actions: from :states:\n",
    "* `agent.predict_proba(states)` - predict probabilities of all actions, a matrix of shape __[len(states), n_actions]__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:56:26.633627Z",
     "iopub.status.busy": "2024-10-06T02:56:26.633447Z",
     "iopub.status.idle": "2024-10-06T02:56:26.994935Z",
     "shell.execute_reply": "2024-10-06T02:56:26.994720Z",
     "shell.execute_reply.started": "2024-10-06T02:56:26.633615Z"
    },
    "id": "wLItY4unG9zL"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, hidden_layer_sizes=(20, 20))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, hidden_layer_sizes=(20, 20))</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='tanh', hidden_layer_sizes=(20, 20))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "agent = MLPClassifier(\n",
    "    hidden_layer_sizes=(20, 20),\n",
    "    activation=\"tanh\",\n",
    ")\n",
    "\n",
    "# initialize agent to the dimension of state space and number of actions\n",
    "agent.partial_fit([env.reset()[0]] * n_actions, range(n_actions), range(n_actions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:56:26.995565Z",
     "iopub.status.busy": "2024-10-06T02:56:26.995395Z",
     "iopub.status.idle": "2024-10-06T02:56:26.997461Z",
     "shell.execute_reply": "2024-10-06T02:56:26.997292Z",
     "shell.execute_reply.started": "2024-10-06T02:56:26.995554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.0333525 ,  0.04922215, -0.02705979, -0.02929757], dtype=float32),\n",
       " array([ 0.0333525 ,  0.04922215, -0.02705979, -0.02929757], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[env.reset()[0]] * n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:56:26.997838Z",
     "iopub.status.busy": "2024-10-06T02:56:26.997740Z",
     "iopub.status.idle": "2024-10-06T02:56:27.016151Z",
     "shell.execute_reply": "2024-10-06T02:56:27.015987Z",
     "shell.execute_reply.started": "2024-10-06T02:56:26.997828Z"
    }
   },
   "outputs": [],
   "source": [
    "def choose_action(\n",
    "    probs\n",
    "):\n",
    "    action = np.random.choice(\n",
    "        np.arange(n_actions),\n",
    "        p=probs\n",
    "    )\n",
    "\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:56:27.201090Z",
     "iopub.status.busy": "2024-10-06T02:56:27.200918Z",
     "iopub.status.idle": "2024-10-06T02:56:27.203330Z",
     "shell.execute_reply": "2024-10-06T02:56:27.203157Z",
     "shell.execute_reply.started": "2024-10-06T02:56:27.201081Z"
    },
    "id": "eyFS3oUmG9zL"
   },
   "outputs": [],
   "source": [
    "def generate_session(env, agent, t_max=1000):\n",
    "    \"\"\"\n",
    "    Play a single game using agent neural network.\n",
    "    Terminate when game finishes or after :t_max: steps\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s, _ = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "\n",
    "        # use agent to predict a vector of action probabilities for state :s:\n",
    "        probs = agent.predict_proba([s])[0]\n",
    "\n",
    "        assert probs.shape == (env.action_space.n,), \"make sure probabilities are a vector (hint: np.reshape)\"\n",
    "\n",
    "        # use the probabilities you predicted to pick an action\n",
    "        # sample proportionally to the probabilities, don't just take the most likely action\n",
    "        a = np.random.choice(np.arange(n_actions), p=probs)\n",
    "        # ^-- hint: try np.random.choice\n",
    "\n",
    "        new_s, r, terminated, truncated, _ = env.step(a)\n",
    "\n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    return states, np.array(actions).tolist(), total_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:56:27.316791Z",
     "iopub.status.busy": "2024-10-06T02:56:27.316607Z",
     "iopub.status.idle": "2024-10-06T02:56:27.319516Z",
     "shell.execute_reply": "2024-10-06T02:56:27.319328Z",
     "shell.execute_reply.started": "2024-10-06T02:56:27.316776Z"
    },
    "id": "4xgrTCgJG9zL",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states: [[-0.04478994 -0.03440018  0.00689948 -0.03128228]\n",
      " [-0.04547795 -0.22962038  0.00627383  0.2635695 ]\n",
      " [-0.05007035 -0.03458855  0.01154522 -0.02712802]\n",
      " [-0.05076212 -0.22987415  0.01100266  0.26917508]\n",
      " [-0.05535961 -0.03491092  0.01638616 -0.02001733]]\n",
      "actions: [0, 1, 0, 1, 1]\n",
      "reward: 5.0\n"
     ]
    }
   ],
   "source": [
    "dummy_states, dummy_actions, dummy_reward = generate_session(env, agent, t_max=5)\n",
    "print(\"states:\", np.stack(dummy_states))\n",
    "print(\"actions:\", dummy_actions)\n",
    "print(\"reward:\", dummy_reward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p85lt16qG9zL"
   },
   "source": [
    "### CEM steps\n",
    "Deep CEM uses exactly the same strategy as the regular CEM, so you can copy your function code from previous notebook.\n",
    "\n",
    "The only difference is that now each observation is not a number but a `float32` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:56:28.450842Z",
     "iopub.status.busy": "2024-10-06T02:56:28.450700Z",
     "iopub.status.idle": "2024-10-06T02:56:28.453008Z",
     "shell.execute_reply": "2024-10-06T02:56:28.452807Z",
     "shell.execute_reply.started": "2024-10-06T02:56:28.450833Z"
    },
    "id": "4On-p7p4G9zL"
   },
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order\n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    If you are confused, see examples below. Please don't assume that states are integers\n",
    "    (they will become different later).\n",
    "    \"\"\"\n",
    "\n",
    "    reward_threshold = np.percentile(rewards_batch, percentile)\n",
    "\n",
    "    elite_states = list()\n",
    "    elite_actions = list()\n",
    "    \n",
    "    for states, actions, reward in zip(states_batch, actions_batch, rewards_batch):\n",
    "        if reward >= reward_threshold:\n",
    "            elite_states.extend(states)\n",
    "            elite_actions.extend(actions)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # print(elite_actions)\n",
    "    # print(elite_states)\n",
    "    # elite_states = states_batch[rewards_batch >= reward_threshold]\n",
    "    # elite_actions = actions_batch[rewards_batch >= reward_threshold]\n",
    "\n",
    "    return elite_states, elite_actions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xc40V4DaG9zM"
   },
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:56:28.850138Z",
     "iopub.status.busy": "2024-10-06T02:56:28.849992Z",
     "iopub.status.idle": "2024-10-06T02:56:28.852544Z",
     "shell.execute_reply": "2024-10-06T02:56:28.852351Z",
     "shell.execute_reply.started": "2024-10-06T02:56:28.850129Z"
    },
    "id": "PPwVKwF7G9zM"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress.\n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "    plt.figure(figsize=[8, 4])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(list(zip(*log))[0], label=\"Mean rewards\")\n",
    "    plt.plot(list(zip(*log))[1], label=\"Reward thresholds\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(rewards_batch, range=reward_range)\n",
    "    plt.vlines(\n",
    "        [np.percentile(rewards_batch, percentile)],\n",
    "        [0],\n",
    "        [100],\n",
    "        label=\"percentile\",\n",
    "        color=\"red\",\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:56:29.049357Z",
     "iopub.status.busy": "2024-10-06T02:56:29.049177Z",
     "iopub.status.idle": "2024-10-06T02:57:45.115054Z",
     "shell.execute_reply": "2024-10-06T02:57:45.114660Z",
     "shell.execute_reply.started": "2024-10-06T02:56:29.049342Z"
    },
    "id": "euK7WRQiG9zM",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = 1000.000, threshold=1000.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You Win! You may stop training now via KeyboardInterrupt.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m log \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# generate new sessions\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     sessions \u001b[38;5;241m=\u001b[39m [\u001b[43mgenerate_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_sessions)]\n\u001b[1;32m      9\u001b[0m     states_batch, actions_batch, rewards_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39msessions)\n\u001b[1;32m     11\u001b[0m     elite_states, elite_actions \u001b[38;5;241m=\u001b[39m select_elites(states_batch, actions_batch, rewards_batch, percentile\u001b[38;5;241m=\u001b[39mpercentile)\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mgenerate_session\u001b[0;34m(env, agent, t_max)\u001b[0m\n\u001b[1;32m      9\u001b[0m s, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(t_max):\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# use agent to predict a vector of action probabilities for state :s:\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     probs \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m probs\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mn,), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake sure probabilities are a vector (hint: np.reshape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# use the probabilities you predicted to pick an action\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# sample proportionally to the probabilities, don't just take the most likely action\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1247\u001b[0m, in \u001b[0;36mMLPClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Probability estimates.\u001b[39;00m\n\u001b[1;32m   1234\u001b[0m \n\u001b[1;32m   1235\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;124;03m    model, where classes are ordered as they are in `self.classes_`.\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1247\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_pass_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1250\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:219\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass_fast\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    217\u001b[0m         hidden_activation(activation)\n\u001b[1;32m    218\u001b[0m output_activation \u001b[38;5;241m=\u001b[39m ACTIVATIONS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_activation_]\n\u001b[0;32m--> 219\u001b[0m \u001b[43moutput_activation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m activation\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.12/site-packages/sklearn/neural_network/_base.py:31\u001b[0m, in \u001b[0;36minplace_logistic\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minplace_logistic\u001b[39m(X):\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the logistic function inplace.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m        The input data.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mlogistic_sigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_sessions = 100\n",
    "percentile = 70\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "    # generate new sessions\n",
    "    sessions = [generate_session(env, agent, t_max=1000) for _ in range(n_sessions)]\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = zip(*sessions)\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile=percentile)\n",
    "\n",
    "    agent.fit(elite_states, elite_actions)\n",
    "\n",
    "    show_progress(\n",
    "        rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch)]\n",
    "    )\n",
    "\n",
    "    if np.mean(rewards_batch) > 190:\n",
    "        print(\"You Win! You may stop training now via KeyboardInterrupt.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeNWKjtsG9zM"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:35:43.672259Z",
     "iopub.status.busy": "2024-10-06T02:35:43.671894Z",
     "iopub.status.idle": "2024-10-06T02:35:43.674590Z",
     "shell.execute_reply": "2024-10-06T02:35:43.674392Z",
     "shell.execute_reply.started": "2024-10-06T02:35:43.672246Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_session(env, agent, t_max=1000):\n",
    "    \"\"\"\n",
    "    Play a single game using agent neural network.\n",
    "    Terminate when game finishes or after :t_max: steps\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s, _ = env.reset()\n",
    "    print(s)\n",
    "\n",
    "    for t in range(t_max):\n",
    "\n",
    "        # use agent to predict a vector of action probabilities for state :s:\n",
    "        probs = agent.predict_proba([s])[0]\n",
    "\n",
    "        assert probs.shape == (env.action_space.n,), \"make sure probabilities are a vector (hint: np.reshape)\"\n",
    "\n",
    "        # use the probabilities you predicted to pick an action\n",
    "        # sample proportionally to the probabilities, don't just take the most likely action\n",
    "        a = np.random.choice(np.arange(n_actions), p=probs)\n",
    "        # print(a)\n",
    "        # ^-- hint: try np.random.choice\n",
    "        \n",
    "        new_s, r, terminated, truncated, _ = env.step(a)\n",
    "\n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    return states, np.array(actions).tolist(), total_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:02:45.811346Z",
     "iopub.status.busy": "2024-10-06T03:02:45.811011Z",
     "iopub.status.idle": "2024-10-06T03:03:01.237072Z",
     "shell.execute_reply": "2024-10-06T03:03:01.236683Z",
     "shell.execute_reply.started": "2024-10-06T03:02:45.811334Z"
    },
    "id": "RJwsWl4kG9zM",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladimir/anaconda3/envs/rl/lib/python3.12/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-0.mp4\n",
      "Moviepy - Building video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-1.mp4.\n",
      "Moviepy - Writing video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-1.mp4\n",
      "Moviepy - Building video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-2.mp4.\n",
      "Moviepy - Writing video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-2.mp4\n",
      "Moviepy - Building video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-3.mp4.\n",
      "Moviepy - Writing video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-3.mp4\n",
      "Moviepy - Building video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-4.mp4.\n",
      "Moviepy - Writing video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-4.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-4.mp4\n",
      "Moviepy - Building video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-5.mp4.\n",
      "Moviepy - Writing video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-5.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-5.mp4\n",
      "Moviepy - Building video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-6.mp4.\n",
      "Moviepy - Writing video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-6.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-6.mp4\n",
      "Moviepy - Building video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-7.mp4.\n",
      "Moviepy - Writing video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-7.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-7.mp4\n",
      "Moviepy - Building video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-8.mp4.\n",
      "Moviepy - Writing video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-8.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-8.mp4\n",
      "Moviepy - Building video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-9.mp4.\n",
      "Moviepy - Writing video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-9.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-9.mp4\n",
      "Moviepy - Building video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-10.mp4.\n",
      "Moviepy - Writing video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-10.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-10.mp4\n",
      "Moviepy - Building video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-11.mp4.\n",
      "Moviepy - Writing video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-11.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  24%|██████▏                   | 120/501 [00:00<00:00, 1165.03it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-11.mp4.\n",
      "Moviepy - Writing video /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-11.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "t:   0%|                                      | 0/501 [00:00<?, ?it/s, now=None]\u001b[A\n",
      "t:  24%|██████▏                   | 120/501 [00:00<00:00, 1198.30it/s, now=None]\u001b[A\n",
      "t:  54%|██████████████▏           | 273/501 [00:00<00:00, 1390.74it/s, now=None]\u001b[A\n",
      "t:  85%|██████████████████████    | 425/501 [00:00<00:00, 1448.10it/s, now=None]\u001b[A\n",
      "t:  24%|██████▏                   | 120/501 [00:00<00:00, 1165.03it/s, now=None]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/vladimir/my_projects/study/Practical_RL/week01_intro/videos/rl-video-episode-11.mp4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecordVideo\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m RecordVideo(\n\u001b[1;32m      6\u001b[0m     env\u001b[38;5;241m=\u001b[39mgym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCartPole-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      7\u001b[0m     video_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./videos\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     episode_trigger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m episode_number: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m env_monitor:\n\u001b[0;32m---> 10\u001b[0m     sessions \u001b[38;5;241m=\u001b[39m [\u001b[43mgenerate_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_monitor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m)]\n",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m, in \u001b[0;36mgenerate_session\u001b[0;34m(env, agent, t_max)\u001b[0m\n\u001b[1;32m     20\u001b[0m a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(np\u001b[38;5;241m.\u001b[39marange(n_actions), p\u001b[38;5;241m=\u001b[39mprobs)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# ^-- hint: try np.random.choice\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m new_s, r, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# record sessions like you did before\u001b[39;00m\n\u001b[1;32m     26\u001b[0m states\u001b[38;5;241m.\u001b[39mappend(s)\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.12/site-packages/gymnasium/wrappers/record_video.py:191\u001b[0m, in \u001b[0;36mRecordVideo.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_vector_env:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m terminateds \u001b[38;5;129;01mor\u001b[39;00m truncateds:\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose_video_recorder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m terminateds[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m truncateds[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose_video_recorder()\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.12/site-packages/gymnasium/wrappers/record_video.py:204\u001b[0m, in \u001b[0;36mRecordVideo.close_video_recorder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecording:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo_recorder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvideo_recorder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecording \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecorded_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.12/site-packages/gymnasium/wrappers/monitoring/video_recorder.py:157\u001b[0m, in \u001b[0;36mVideoRecorder.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m     clip \u001b[38;5;241m=\u001b[39m ImageSequenceClip(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecorded_frames, fps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframes_per_sec)\n\u001b[1;32m    156\u001b[0m     moviepy_logger \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_logger \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 157\u001b[0m     \u001b[43mclip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_videofile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmoviepy_logger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# No frames captured. Set metadata.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m<decorator-gen-70>:2\u001b[0m, in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, temp_audiofile_path, rewrite_audio, remove_temp, write_logfile, threads, ffmpeg_params, logger, pix_fmt)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.12/site-packages/moviepy/decorators.py:56\u001b[0m, in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<decorator-gen-69>:2\u001b[0m, in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, temp_audiofile_path, rewrite_audio, remove_temp, write_logfile, threads, ffmpeg_params, logger, pix_fmt)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.12/site-packages/moviepy/decorators.py:135\u001b[0m, in \u001b[0;36muse_clip_fps_by_default\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m    132\u001b[0m new_a \u001b[38;5;241m=\u001b[39m [fun(arg) \u001b[38;5;28;01mif\u001b[39;00m (name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfps\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m arg \u001b[38;5;28;01mfor\u001b[39;00m (arg, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, names)]\n\u001b[1;32m    133\u001b[0m new_kw \u001b[38;5;241m=\u001b[39m {k: fun(v) \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfps\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m v \u001b[38;5;28;01mfor\u001b[39;00m (k, v) \u001b[38;5;129;01min\u001b[39;00m k\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<decorator-gen-68>:2\u001b[0m, in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, temp_audiofile_path, rewrite_audio, remove_temp, write_logfile, threads, ffmpeg_params, logger, pix_fmt)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.12/site-packages/moviepy/decorators.py:24\u001b[0m, in \u001b[0;36mconvert_masks_to_RGB\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clip\u001b[38;5;241m.\u001b[39mismask:\n\u001b[1;32m     23\u001b[0m     clip \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mto_RGB()\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<decorator-gen-67>:2\u001b[0m, in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, temp_audiofile_path, rewrite_audio, remove_temp, write_logfile, threads, ffmpeg_params, logger, pix_fmt)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.12/site-packages/moviepy/decorators.py:89\u001b[0m, in \u001b[0;36mpreprocess_args.<locals>.wrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     84\u001b[0m new_a \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     85\u001b[0m     fun(arg) \u001b[38;5;28;01mif\u001b[39;00m (name \u001b[38;5;129;01min\u001b[39;00m varnames) \u001b[38;5;129;01mand\u001b[39;00m (arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01melse\u001b[39;00m arg\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (arg, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, names)\n\u001b[1;32m     87\u001b[0m ]\n\u001b[1;32m     88\u001b[0m new_kw \u001b[38;5;241m=\u001b[39m {k: fun(v) \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m varnames \u001b[38;5;28;01melse\u001b[39;00m v \u001b[38;5;28;01mfor\u001b[39;00m (k, v) \u001b[38;5;129;01min\u001b[39;00m kw\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.12/site-packages/moviepy/video/VideoClip.py:343\u001b[0m, in \u001b[0;36mVideoClip.write_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, temp_audiofile_path, rewrite_audio, remove_temp, write_logfile, threads, ffmpeg_params, logger, pix_fmt)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m make_audio:\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mwrite_audiofile(\n\u001b[1;32m    333\u001b[0m         audiofile,\n\u001b[1;32m    334\u001b[0m         audio_fps,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m         logger\u001b[38;5;241m=\u001b[39mlogger,\n\u001b[1;32m    341\u001b[0m     )\n\u001b[0;32m--> 343\u001b[0m \u001b[43mffmpeg_write_video\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcodec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbitrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbitrate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_logfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_logfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43maudiofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudiofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mffmpeg_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mffmpeg_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpix_fmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpix_fmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remove_temp \u001b[38;5;129;01mand\u001b[39;00m make_audio:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(audiofile):\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.12/site-packages/moviepy/video/io/ffmpeg_writer.py:265\u001b[0m, in \u001b[0;36mffmpeg_write_video\u001b[0;34m(clip, filename, fps, codec, bitrate, preset, withmask, write_logfile, audiofile, threads, ffmpeg_params, logger, pix_fmt)\u001b[0m\n\u001b[1;32m    262\u001b[0m                 mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m             frame \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdstack([frame, mask])\n\u001b[0;32m--> 265\u001b[0m         \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m write_logfile:\n\u001b[1;32m    268\u001b[0m     logfile\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.12/site-packages/moviepy/video/io/ffmpeg_writer.py:143\u001b[0m, in \u001b[0;36mFFMPEG_VideoWriter.write_frame\u001b[0;34m(self, img_array)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Writes one frame in the file.\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    145\u001b[0m     _, ffmpeg_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mcommunicate()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  24%|██████▏                   | 120/501 [00:13<00:00, 1165.03it/s, now=None]"
     ]
    }
   ],
   "source": [
    "# Record sessions\n",
    "\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "with RecordVideo(\n",
    "    env=gym.make(\"CartPole-v1\", render_mode=\"rgb_array\"),\n",
    "    video_folder=\"./videos\",\n",
    "    episode_trigger=lambda episode_number: True,\n",
    ") as env_monitor:\n",
    "    sessions = [generate_session(env_monitor, agent) for _ in range(20)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:10:45.526447Z",
     "iopub.status.busy": "2024-10-06T03:10:45.526303Z",
     "iopub.status.idle": "2024-10-06T03:10:45.528834Z",
     "shell.execute_reply": "2024-10-06T03:10:45.528663Z",
     "shell.execute_reply.started": "2024-10-06T03:10:45.526435Z"
    },
    "id": "kLPXdME7G9zN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"videos/rl-video-episode-10.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show video. This may not work in some setups. If it doesn't\n",
    "# work for you, you can download the videos and view them locally.\n",
    "\n",
    "from pathlib import Path\n",
    "from base64 import b64encode\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_paths = sorted([s for s in Path(\"videos\").iterdir() if s.suffix == \".mp4\"])\n",
    "video_path = video_paths[3]  # You can also try other indices\n",
    "\n",
    "\n",
    "data_url = str(video_path)\n",
    "\n",
    "HTML(\n",
    "    \"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\n",
    "        data_url\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d_3oOQ1G9zN"
   },
   "source": [
    "# Homework part I\n",
    "\n",
    "### Tabular crossentropy method\n",
    "\n",
    "You may have noticed that the taxi problem quickly converges from -100 to a near-optimal score and then descends back into -50/-100. This is in part because the environment has some innate randomness. Namely, the starting points of passenger/driver change from episode to episode.\n",
    "\n",
    "### Tasks\n",
    "- __1.1__ (2 pts) Find out how the algorithm performance changes if you use a different `percentile` and/or `n_sessions`. Provide here some figures so we can see how the hyperparameters influence the performance.\n",
    "- __1.2__ (1 pts) Tune the algorithm to end up with positive average score.\n",
    "\n",
    "It's okay to modify the existing code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L88LySiVG9zN"
   },
   "source": [
    "```<Describe what you did here>```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LpAJc4rG9zN"
   },
   "source": [
    "# Homework part II\n",
    "\n",
    "### Deep crossentropy method\n",
    "\n",
    "By this moment, you should have got enough score on [CartPole-v0](https://gymnasium.farama.org/environments/classic_control/cart_pole/) to consider it solved (see the link). It's time to try something harder.\n",
    "\n",
    "* if you have any trouble with CartPole-v0 and feel stuck, feel free to ask us or your peers for help.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* __2.1__ (3 pts) Pick one of environments: `MountainCar-v0` or `LunarLander-v2`.\n",
    "  * For MountainCar, get average reward of __at least -150__\n",
    "  * For LunarLander, get average reward of __at least +50__\n",
    "\n",
    "See the tips section below, it's kinda important.\n",
    "__Note:__ If your agent is below the target score, you'll still get some of the points depending on the result, so don't be afraid to submit it.\n",
    "  \n",
    "  \n",
    "* __2.2__ (up to 6 pts) Devise a way to speed up training against the default version\n",
    "  * Obvious improvement: use [`joblib`](https://joblib.readthedocs.io/en/latest/). However, note that you will probably need to spawn a new environment in each of the workers instead of passing it via pickling. (2 pts)\n",
    "  * Try re-using samples from 3-5 last iterations when computing threshold and training. (2 pts)\n",
    "  * Obtain __-100__ at `MountainCar-v0` or __+200__ at `LunarLander-v2` (2 pts). Feel free to experiment with hyperparameters, architectures, schedules etc.\n",
    "  \n",
    "__Please list what you did in Anytask submission form__. This reduces probability that somebody misses something.\n",
    "  \n",
    "  \n",
    "### Tips\n",
    "* Gymnasium pages: [MountainCar](https://gymnasium.farama.org/environments/classic_control/mountain_car/), [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/)\n",
    "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
    " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 10% are better, than if you use percentile 20% as threshold, R >= threshold __fails to cut off bad sessions__ while R > threshold works alright.\n",
    "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
    "* If you use old _swig_ lib for LunarLander-v2, you may get an error. See this [issue](https://github.com/openai/gym/issues/100) for solution.\n",
    "* If it doesn't train, it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
    "* 20-neuron network is probably not enough, feel free to experiment.\n",
    "\n",
    "You may find the following snippet useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcjz-nm_G9zN"
   },
   "outputs": [],
   "source": [
    "def visualize_mountain_car(env, agent):\n",
    "    # Compute policy for all possible x and v (with discretization)\n",
    "    xs = np.linspace(env.min_position, env.max_position, 100)\n",
    "    vs = np.linspace(-env.max_speed, env.max_speed, 100)\n",
    "\n",
    "    grid = np.dstack(np.meshgrid(xs, vs[::-1])).transpose(1, 0, 2)\n",
    "    grid_flat = grid.reshape(len(xs) * len(vs), 2)\n",
    "    probs = (\n",
    "        agent.predict_proba(grid_flat).reshape(len(xs), len(vs), 3).transpose(1, 0, 2)\n",
    "    )\n",
    "\n",
    "    # # The above code is equivalent to the following:\n",
    "    # probs = np.empty((len(vs), len(xs), 3))\n",
    "    # for i, v in enumerate(vs[::-1]):\n",
    "    #     for j, x in enumerate(xs):\n",
    "    #         probs[i, j, :] = agent.predict_proba([[x, v]])[0]\n",
    "\n",
    "    # Draw policy\n",
    "    f, ax = plt.subplots(figsize=(7, 7))\n",
    "    ax.imshow(\n",
    "        probs,\n",
    "        extent=(env.min_position, env.max_position, -env.max_speed, env.max_speed),\n",
    "        aspect=\"auto\",\n",
    "    )\n",
    "    ax.set_title(\"Learned policy: red=left, green=nothing, blue=right\")\n",
    "    ax.set_xlabel(\"position (x)\")\n",
    "    ax.set_ylabel(\"velocity (v)\")\n",
    "\n",
    "    # Sample a trajectory and draw it\n",
    "    states, actions, _ = generate_session(env, agent)\n",
    "    states = np.array(states)\n",
    "    ax.plot(states[:, 0], states[:, 1], color=\"white\")\n",
    "\n",
    "    # Draw every 3rd action from the trajectory\n",
    "    for (x, v), a in zip(states[::3], actions[::3]):\n",
    "        if a == 0:\n",
    "            plt.arrow(x, v, -0.1, 0, color=\"white\", head_length=0.02)\n",
    "        elif a == 2:\n",
    "            plt.arrow(x, v, 0.1, 0, color=\"white\", head_length=0.02)\n",
    "\n",
    "\n",
    "with gym.make(\"MountainCar-v0\", render_mode=\"rgb_arrary\").env as env:\n",
    "    visualize_mountain_car(env, agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dzk41lDPG9zO"
   },
   "source": [
    "### Bonus tasks\n",
    "\n",
    "* __2.3 bonus__ (2 pts) Try to find a network architecture and training params that solve __both__ environments above (_Points depend on implementation. If you attempted this task, please mention it in Anytask submission._)\n",
    "\n",
    "* __2.4 bonus__ (4 pts) Solve continuous action space task with `MLPRegressor` or similar.\n",
    "  * Since your agent only predicts the \"expected\" action, you will have to add noise to ensure exploration.\n",
    "  * Choose one of [MountainCarContinuous-v0](https://gymnasium.farama.org/environments/classic_control/mountain_car_continuous/) (90+ pts to solve), [LunarLanderContinuous-v2](https://gymnasium.farama.org/environments/box2d/lunar_lander/) (`env = gym.make(\"LunarLander-v2\", continuous=True)`)(200+ pts to solve)\n",
    "  * 4 points for solving. Slightly less for getting some results below solution threshold. Note that discrete and continuous environments may have slightly different rules, aside from action spaces."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
